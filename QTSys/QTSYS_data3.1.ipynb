{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tushare.pro.client.DataApi object at 0x7ff42c047e10>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import heapq \n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import threading\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,accuracy_score,auc \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import date2num\n",
    "import cv2\n",
    "import faiss \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import baostock as bs#pip install baostock\n",
    "import mplfinance as mpf #pip install mplfinance\n",
    "import easyquotation #pip install easyquotation\n",
    "import tushare as ts # pip install tushare\n",
    "tstoken='2621bdfffbde695d0d256a69a71d9344c94c1d8a58f389cd391ceeeb' #youer token\n",
    "ts.set_token(tstoken)\n",
    "pro = ts.pro_api()\n",
    "print(pro)\n",
    "torch.cuda.set_device(1)\n",
    "print (torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Training model and output database(faiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868 / 868 best_loss = 0.013971\n",
      " 86 / 87 Completed buliding index in 23 seconds\n"
     ]
    }
   ],
   "source": [
    "#Generate Dataset\n",
    "root_dir = '/data/fjsdata/qtsys/img/' #the path of images\n",
    "data = pd.read_csv('/data/fjsdata/qtsys/label.csv') \n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle\n",
    "#Dataset\n",
    "trN,trI, trY =[], [],[]\n",
    "for _, row in data.iterrows():\n",
    "    try:\n",
    "        image_path = os.path.join(root_dir, row['name'])\n",
    "        img = cv2.resize(cv2.imread(image_path).astype(np.float32), (256, 256))#(1600,800,3)->(256,256,3)\n",
    "        trN.append(row['name'])\n",
    "        trI.append(img)\n",
    "        if row['label']=='B':\n",
    "            trY.append(0) #buy\n",
    "        else:# row['label']=='S':\n",
    "            trY.append(1) #sell\n",
    "    except:\n",
    "        print(iname+\":\"+str(image_path))\n",
    "    sys.stdout.write('\\r{} / {} '.format(len(trY),data.shape[0]))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "#Generate image pairs for model\n",
    "def onlineGenImgPairs():\n",
    "    if (len(trY) % 2) == 0: spls = len(trY)\n",
    "    else:  spls = len(trY)-1\n",
    "    idx_sf = random.sample(range(0, spls),spls)\n",
    "    trI1_sf, trI2_sf, trY1_sf, trY2_sf = [],[],[],[]\n",
    "    flag = 0\n",
    "    for i in idx_sf:\n",
    "        if flag==0:\n",
    "            trI1_sf.append(trI[i])\n",
    "            trY1_sf.append(trY[i])\n",
    "            flag =1\n",
    "        else:\n",
    "            trI2_sf.append(trI[i])\n",
    "            trY2_sf.append(trY[i])\n",
    "            flag =0\n",
    "    trY_sf = np.where((np.array(trY1_sf)-np.array(trY2_sf))!=0,1,0)\n",
    "    return np.array(trI1_sf),np.array(trI2_sf),trY_sf\n",
    "\n",
    "#define model: ASH\n",
    "class SpatialAttention(nn.Module):#spatial attention layer\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        self.downsample_layer = None\n",
    "        self.do_downsample = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.do_downsample = True\n",
    "            self.downsample_layer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.net(x)\n",
    "\n",
    "        if self.do_downsample:\n",
    "            identity = self.downsample_layer(x)\n",
    "\n",
    "        return F.relu(out + identity, inplace=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            \n",
    "class ASHNet(nn.Module):\n",
    "    def __init__(self, code_size: int):\n",
    "        super().__init__()\n",
    "        #Resnet\n",
    "        self.net = nn.Sequential(\n",
    "            ResBlock(in_channels=3, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16),\n",
    "            ResBlock(in_channels=16, out_channels=16, stride=2),\n",
    "        ) \n",
    "        #Attention \n",
    "        self.sa = SpatialAttention() \n",
    "        #fully connected\n",
    "        self.linear = nn.Sequential(\n",
    "            #nn.Linear(16*128*128, 4096),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Linear(16*128*128, code_size),\n",
    "            #nn.ReLU(inplace=True) #nn.Tanh()#[-1,1]\n",
    "        )\n",
    "        \n",
    "        # initialize weights\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.sa(x)*x\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "#dfine loss function:pairwise loss            \n",
    "class HashLossFunc(nn.Module):\n",
    "    def __init__(self, margin=0.5, alpha=0.01):\n",
    "        super(HashLossFunc, self).__init__()\n",
    "        self.alpha = alpha #regularization\n",
    "        self.margin = margin #margin threshold\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.l1_loss = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    def forward(self,h1,h2,y):    \n",
    "        margin_val = self.margin * h1.shape[1]\n",
    "        squared_loss = torch.mean(self.mse_loss(h1, h2), dim=1)\n",
    "        # T1: 0.5 * (1 - y) * dist(x1, x2)\n",
    "        positive_pair_loss = (0.5 * (1 - y) * squared_loss)\n",
    "        mean_positive_pair_loss = torch.mean(positive_pair_loss)\n",
    "        # T2: 0.5 * y * max(margin - dist(x1, x2), 0)\n",
    "        zeros = torch.zeros_like(squared_loss)\n",
    "        marginMat = margin_val * torch.ones_like(squared_loss)\n",
    "        negative_pair_loss = 0.5 * y * torch.max(zeros, marginMat - squared_loss)\n",
    "        mean_negative_pair_loss = torch.mean(negative_pair_loss)\n",
    "\n",
    "        # T3: alpha(dst_l1(abs(x1), 1)) + dist_l1(abs(x2), 1)))\n",
    "        mean_value_regularization = self.alpha * (\n",
    "                self.l1_loss(torch.abs(h1), torch.ones_like(h1)) +\n",
    "                self.l1_loss(torch.abs(h2), torch.ones_like(h2)))\n",
    "\n",
    "        loss = mean_positive_pair_loss + mean_negative_pair_loss + mean_value_regularization\n",
    "        return loss\n",
    "\n",
    "\n",
    "#train model\n",
    "hash_size=12\n",
    "model = ASHNet(code_size=hash_size).cuda()\n",
    "criterion  = HashLossFunc(margin=0.5).cuda() #define loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #define optimizer\n",
    "#train model\n",
    "best_net, best_loss = None, float('inf')\n",
    "batchSize = 10\n",
    "for epoch in range(50):#iteration\n",
    "    trI1_sf, trI2_sf, trY_sf = onlineGenImgPairs()\n",
    "    losses = []\n",
    "    num_batches = len(trY_sf) // batchSize +1\n",
    "    for i in range(num_batches):\n",
    "        optimizer.zero_grad()#grad vanish\n",
    "        min_idx = i * batchSize\n",
    "        max_idx = np.min([len(trY_sf), (i+1)*batchSize])\n",
    "        I1_batch = torch.from_numpy(trI1_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        I2_batch = torch.from_numpy(trI2_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        Y_batch = torch.from_numpy(trY_sf[min_idx:max_idx]).type(torch.FloatTensor).cuda()\n",
    "        #forword\n",
    "        X1_batch = model(I1_batch.permute(0, 3, 1, 2))#permute the dims of matrix\n",
    "        X2_batch = model(I2_batch.permute(0, 3, 1, 2))\n",
    "        #binary-like loss\n",
    "        loss = criterion(X1_batch,X2_batch,Y_batch)\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update parameters\n",
    "        optimizer.step()\n",
    "        #show loss\n",
    "        #sys.stdout.write('\\r {} / {} : loss = {}'.format(i+1, num_batches, float('%0.6f'%loss.item())))\n",
    "        #sys.stdout.flush()     \n",
    "        losses.append(loss.item())\n",
    "    #print(\"Eopch: %5d mean_loss = %.6f\" % (epoch + 1, np.mean(losses)))\n",
    "    if np.mean(losses) < best_loss:\n",
    "        best_loss = np.mean(losses)\n",
    "        best_net = copy.deepcopy(model)\n",
    "print(\"best_loss = %.6f\" % (best_loss))\n",
    "\n",
    "#release gpu memory\n",
    "model = model.cpu()\n",
    "loss=loss.cpu()\n",
    "torch.cuda.empty_cache()\n",
    "#output the feature with best model\n",
    "#torch.cuda.synchronize()\n",
    "batchSize = 10\n",
    "num_batches = len(trI) // batchSize +1\n",
    "trF = []\n",
    "for i in range(num_batches):\n",
    "    min_idx = i * batchSize\n",
    "    max_idx = np.min([len(trI), (i+1)*batchSize])\n",
    "    I_batch = torch.from_numpy(np.array(trI[min_idx: max_idx])).type(torch.FloatTensor).cuda()\n",
    "    X_batch = best_net(I_batch.permute(0, 3, 1, 2))#forword\n",
    "    X_batch = torch.tanh(X_batch) #[-1,1]\n",
    "    I_batch = I_batch.cpu()\n",
    "    X_batch = X_batch.cpu()\n",
    "    torch.cuda.empty_cache()#release gpu memory\n",
    "    trF.extend(X_batch.data.numpy().tolist())\n",
    "    sys.stdout.write('\\r {} / {} '.format(i, num_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# buliding index for retrieval\n",
    "tstart = time.time()\n",
    "cpu_index = faiss.IndexFlatL2(hash_size) #\n",
    "gpu_index = faiss.index_cpu_to_all_gpus(cpu_index) #make all gpu usable\n",
    "gpu_index.add(np.ascontiguousarray(trF, dtype=np.float32)) #add data(must be float32) to index\n",
    "elapsed = time.time() - tstart    \n",
    "print('Completed buliding index in %d seconds' % int(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Online Generate Kline picture and predict whether buy or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/root/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "Exception in thread Thread-48757:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/root/miniconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-42-88eb8fd27fe4>\", line 85, in plot_predict_thread\n",
      "    teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-3-fdab9529c768>\", line 118, in forward\n",
      "    x = self.net(x)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-3-fdab9529c768>\", line 83, in forward\n",
      "    out = self.net(x)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 338, in forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: Expected tensor for argument #1 'input' to have the same device as tensor for argument #2 'weight'; but device 0 does not equal 1 (while checking arguments for cudnn_convolution)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-88eb8fd27fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#collect real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAll_His_KLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mreal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'now'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAll_Now_KLine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/easyquotation/basequotation.py\u001b[0m in \u001b[0;36mreal\u001b[0;34m(self, stock_codes, prefix)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mstock_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_stock_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmarket_snapshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/easyquotation/basequotation.py\u001b[0m in \u001b[0;36mget_stock_data\u001b[0;34m(self, stock_list, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;34m\"\"\"获取并格式化股票信息\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_stock_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_response_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/easyquotation/basequotation.py\u001b[0m in \u001b[0;36m_fetch_stock_data\u001b[0;34m(self, stock_list)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stocks_by_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Calculate MACD\n",
    "def cal_macd_system(data,short_,long_,m):\n",
    "    '''\n",
    "    data=['Open','High','Low','Close']\n",
    "    parameter: short_,long_,m\n",
    "    return:data=['Open','High','Low','Close','diff','dea','macd']\n",
    "    '''\n",
    "    data['diff']=data['Close'].ewm(adjust=False,alpha=2/(short_+1),ignore_na=True).mean()-\\\n",
    "                data['Close'].ewm(adjust=False,alpha=2/(long_+1),ignore_na=True).mean()\n",
    "    data['dea']=data['diff'].ewm(adjust=False,alpha=2/(m+1),ignore_na=True).mean()\n",
    "    data['macd']=2*(data['diff']-data['dea'])\n",
    "    return data\n",
    "def macd_zero(macd):\n",
    "    pos_signal, neg_signal = [],[]\n",
    "    for idx,value in macd.iteritems():\n",
    "        if value > 0:\n",
    "            pos_signal.append(value)\n",
    "            neg_signal.append(np.nan)\n",
    "        else:\n",
    "            neg_signal.append(value)\n",
    "            pos_signal.append(np.nan)\n",
    "    return pos_signal,neg_signal\n",
    "\n",
    "#http://tushare.org/trading.html               \n",
    "#https://tushare.pro/document/2\n",
    "def his_kline():\n",
    "    #read stocks information\n",
    "    df_stocks = pro.stock_basic(exchange='', list_status='L', fields='symbol')\n",
    "    #read k data\n",
    "    today  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%Y%m%d')#UTC->CTS +8hours\n",
    "    df_cal = pro.trade_cal(exchange='', start_date='20200101', end_date=today)\n",
    "    df_cal =df_cal[df_cal['is_open']==1].reset_index(drop=True)\n",
    "    edate = df_cal[-21:][-1:]['cal_date'].tolist()[0] #last-1\n",
    "    sdate = df_cal[-21:].head(1)['cal_date'].tolist()[0] #first\n",
    "    edate = datetime.datetime.strptime(edate, '%Y%m%d').strftime('%Y-%m-%d') #turn to datetime\n",
    "    sdate = datetime.datetime.strptime(sdate, '%Y%m%d').strftime('%Y-%m-%d')  #turn to datetime\n",
    "    fields= \"Open,High,Low,Close\"\n",
    "    All_His_KLine = {}\n",
    "    for code in df_stocks['symbol'].tolist()[0:10]:\n",
    "        if code[0]=='6': bs_code = 'sh.'+ code\n",
    "        elif code[0]=='0' or code[0]=='3': bs_code = 'sz.'+ code\n",
    "        else: continue\n",
    "        #read transaction data\n",
    "        rs = bs.query_history_k_data(code=bs_code, fields=fields, \\\n",
    "                                    start_date=sdate, end_date=edate, \\\n",
    "                                    frequency=\"30\",adjustflag=\"3\") #40days，one k line per 60 minutes\n",
    "        data_list = []\n",
    "        while (rs.error_code == '0') & rs.next():\n",
    "            data_list.append(rs.get_row_data())\n",
    "        result = pd.DataFrame(data_list, columns=rs.fields)\n",
    "        result=result.apply(pd.to_numeric, errors='ignore')\n",
    "        if result.shape[0] ==160:\n",
    "            All_His_KLine[code]=result\n",
    "    return All_His_KLine,today\n",
    "\n",
    "def plot_predict_thread(All_His_KLine,All_Now_KLine,today):\n",
    "    for code in All_His_KLine.keys():\n",
    "        his_kline = All_His_KLine[code] #dataframe\n",
    "        if code in All_Now_KLine.keys(): #not open,\n",
    "            price_list = All_Now_KLine[code]\n",
    "            his_kline.loc[his_kline.shape[0]]={'Open':price_list[0],'High':np.array(price_list).max(),\\\n",
    "                                                'Low':np.array(price_list).min(),'Close':price_list[-1]}\n",
    "        df_kline = his_kline[-160:] #get last 160\n",
    "        #plot\n",
    "        df_kline.index=pd.to_datetime(df_kline.index)#turn index to datatime\n",
    "        df_kline = cal_macd_system(df_kline,12,26,9)\n",
    "        pos_macd, neg_macd  = macd_zero(df_kline['macd']) \n",
    "        apds = [ mpf.make_addplot(df_kline['diff'],panel='lower',color='b'),\n",
    "                     mpf.make_addplot(df_kline['dea'],panel='lower',color='y'),\n",
    "                     mpf.make_addplot(pos_macd,panel='lower',color='r',scatter=True),\n",
    "                     mpf.make_addplot(neg_macd,panel='lower',color='g',scatter=True)\n",
    "                    ]\n",
    "        kwargs = dict(type='candle',figratio =(16,8),volume=False,figscale=1)#line，mav=(5,10)\n",
    "        now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "        file_name = code+'-'+today+'-'+now_time+'.png'\n",
    "        Kline_path ='/data/fjsdata/qtsys/real/'+file_name\n",
    "        save = dict(fname=Kline_path,dpi=100, pad_inches=0.2)\n",
    "        mpf.plot(df_kline,**kwargs,addplot=apds,style='sas',savefig=save)#charles\n",
    "        plt.close()\n",
    "        #predict\n",
    "        Kline_img = cv2.resize(cv2.imread(Kline_path).astype(np.float32), (256, 256)) #read image \n",
    "        teI = []\n",
    "        teI.append(Kline_img)\n",
    "        teI = torch.from_numpy(np.array(teI)).type(torch.FloatTensor).cuda()#output feature with model\n",
    "        teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
    "        teI = torch.tanh(teI) #[-1,1]\n",
    "        teI = teI.cpu().data.numpy().tolist()\n",
    "        scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "        if scores.flatten()[0]< 0.001: #similarity for sell\n",
    "            label = trY[neighbors.flatten()[0]] \n",
    "            name =  trN[neighbors.flatten()[0]]\n",
    "            with open('/data/fjsdata/qtsys/real.csv','a+') as f:\n",
    "                csv_write = csv.writer(f)\n",
    "                if label == 1:\n",
    "                    print('%s-S<-->%s'%(file_name,name))\n",
    "                    csv_write.writerow([file_name,'S'])\n",
    "                elif (label == 0 and scores.flatten()[0]< 0.0005): #similarity for buy\n",
    "                    print('%s-B<-->%s'%(file_name,name))\n",
    "                    csv_write.writerow([file_name,'B'])          \n",
    "                else:os.remove(Kline_path) #remove the image file if no handle\n",
    "        else: \n",
    "            print('his:%s'%(code))\n",
    "            os.remove(Kline_path) #remove the image file if no handle  \n",
    "            \n",
    "#https://github.com/shidenggui/easyquotation\n",
    "#trans_time = ['9:00:00','10:00:00','10:30:00','11:00:00','13:00:00','13:30:00','14:00:00','14:30:00']\n",
    "lg = bs.login() #login\n",
    "All_His_KLine,today = his_kline()#get history kline\n",
    "All_Now_KLine = {}\n",
    "quotation = easyquotation.use('sina')\n",
    "open_flag = True\n",
    "while True:\n",
    "    if open_flag: #open am and pm\n",
    "        t = threading.Thread(target=plot_predict_thread,args=(All_His_KLine,All_Now_KLine,today))\n",
    "        t.start()\n",
    "        open_flag = False\n",
    "        tstart = time.time()\n",
    "    else:\n",
    "        #time.sleep(2)#2seconds waiting\n",
    "        elapsed = time.time() - tstart \n",
    "        if elapsed>30*60: #plot Kline and predict,30minutes\n",
    "            t = threading.Thread(target=plot_predict_thread,args=(All_His_KLine,All_Now_KLine,today))\n",
    "            t.start()\n",
    "            tstart = time.time()\n",
    "            All_Now_KLine[code]=[] #empty\n",
    "        else: #collect real data\n",
    "            for code in All_His_KLine.keys():\n",
    "                real_data = quotation.real(code)\n",
    "                price =  list(real_data.values())[0]['now']\n",
    "                if code in All_Now_KLine.keys():\n",
    "                    price_list = All_Now_KLine[code]\n",
    "                    if price not in price_list:\n",
    "                        price_list.append(price)\n",
    "                        All_Now_KLine[code] = price_list\n",
    "                else:\n",
    "                    All_Now_KLine.setdefault(code,[price])#value is list\n",
    "bs.logout()#logout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Getting data:]#############################################################################[Getting data:]#############################Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=29': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=29': failed to load HTTP resource\n",
      "##Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=31': failed to load HTTP resource\n",
      "#Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "Error reading file 'http://vip.stock.finance.sina.com.cn/quotes_service/view/vMS_tradedetail.php?symbol=sz000002&date=2020-03-23&page=32': failed to load HTTP resource\n",
      "获取失败，请检查网络.\n",
      "HTTP Error 456: \n",
      "HTTP Error 456: \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "获取失败，请检查网络.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-45dc8e6d679c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mdf_kline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_kline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_kline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf_kline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mkline_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mdf_today\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_today_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#get today\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mnow_time_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mnow_time_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnow_time_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/tushare/stock/trading.py\u001b[0m in \u001b[0;36mget_today_ticks\u001b[0;34m(code, retry_count, pause)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNETWORK_URL_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: 获取失败，请检查网络."
     ]
    }
   ],
   "source": [
    "#Calculate MACD\n",
    "def cal_macd_system(data,short_,long_,m):\n",
    "    '''\n",
    "    data=['Open','High','Low','Close']\n",
    "    parameter: short_,long_,m\n",
    "    return:data=['Open','High','Low','Close','diff','dea','macd']\n",
    "    '''\n",
    "    data['diff']=data['Close'].ewm(adjust=False,alpha=2/(short_+1),ignore_na=True).mean()-\\\n",
    "                data['Close'].ewm(adjust=False,alpha=2/(long_+1),ignore_na=True).mean()\n",
    "    data['dea']=data['diff'].ewm(adjust=False,alpha=2/(m+1),ignore_na=True).mean()\n",
    "    data['macd']=2*(data['diff']-data['dea'])\n",
    "    return data\n",
    "def macd_zero(macd):\n",
    "    pos_signal, neg_signal = [],[]\n",
    "    for idx,value in macd.iteritems():\n",
    "        if value > 0:\n",
    "            pos_signal.append(value)\n",
    "            neg_signal.append(np.nan)\n",
    "        else:\n",
    "            neg_signal.append(value)\n",
    "            pos_signal.append(np.nan)\n",
    "    return pos_signal,neg_signal\n",
    "\n",
    "#http://tushare.org/trading.html               \n",
    "#https://tushare.pro/document/2\n",
    "#https://github.com/shidenggui/easyquotation\n",
    "#iteration when on charge\n",
    "frs = 30  #Get the 30 minute K-line for the last 20 trading days\n",
    "kline_len = 160 #length of kline\n",
    "trans_time = ['9:30:00','10:00:00','10:30:00','11:00:00','13:00:00','13:30:00','14:00:00','14:30:00']\n",
    "while True:\n",
    "    now_time  = (datetime.datetime.now()+datetime.timedelta(hours=8)).strftime('%H:%M:%S')#UTC->CTS +8hours\n",
    "    now_time = '14:30:00'\n",
    "    if now_time in trans_time:   \n",
    "        df_stocks = pro.stock_basic(exchange='', list_status='L', fields='symbol,name')\n",
    "        for code in df_stocks['symbol'].tolist():\n",
    "            today =datetime.datetime.now().strftime('%Y%m%d') \n",
    "            df_cal = pro.trade_cal(exchange='', start_date='20200101', end_date=today)\n",
    "            df_cal =df_cal[df_cal['is_open']==1].reset_index(drop=True)\n",
    "            edate = df_cal[-22:][-1:]['cal_date'].tolist()[0] #last-1\n",
    "            sdate = df_cal[-22:].head(1)['cal_date'].tolist()[0] #first\n",
    "            edate = datetime.datetime.strptime(edate, '%Y%m%d').strftime('%Y-%m-%d') #turn to datetime\n",
    "            sdate = datetime.datetime.strptime(sdate, '%Y%m%d').strftime('%Y-%m-%d')  #turn to datetime\n",
    "            df_kline = ts.get_hist_data(code, ktype=str(frs), start=sdate,end=edate)[['open','high','low','close']].reset_index(drop=True)\n",
    "            df_kline = df_kline.sort_index(ascending=False) #inverse\n",
    "            if (df_kline is not None and df_kline.shape[0] ==kline_len): \n",
    "                df_today = ts.get_today_ticks(code)[['time','price']] #get today \n",
    "                now_time_end = datetime.datetime.strptime(now_time, '%H:%M:%S')\n",
    "                now_time_start = (now_time_end + datetime.timedelta(minutes=-30))\n",
    "                df_today['flag']= df_today['time'].apply(lambda x: 1 if now_time_start<datetime.datetime.strptime(x, '%H:%M:%S')<now_time_end else 0)\n",
    "                df_today = df_today[df_today['flag']==1]\n",
    "                if (len(df_today))>0:\n",
    "                    df_kline.loc[df_kline.shape[0]]={'open':df_today['price'].tolist()[0],'high':df_today['price'].max(),\\\n",
    "                                         'low':df_today['price'].min(),'close':df_today['price'].tolist()[-1]}\n",
    "                    df_kline = df_kline[-160:]\n",
    "                    df_kline = df_kline.rename(columns={\"open\": \"Open\", \"high\": \"High\", \"low\": \"Low\", \"close\": \"Close\"})\n",
    "                    df_kline.index=pd.to_datetime(df_kline.index)#turn index to datatime\n",
    "                    df_kline = cal_macd_system(df_kline,12,26,9)\n",
    "                    pos_macd, neg_macd  = macd_zero(df_kline['macd']) \n",
    "                    apds = [ mpf.make_addplot(df_kline['diff'],panel='lower',color='b'),\n",
    "                                 mpf.make_addplot(df_kline['dea'],panel='lower',color='y'),\n",
    "                                 mpf.make_addplot(pos_macd,panel='lower',color='r',scatter=True),\n",
    "                                 mpf.make_addplot(neg_macd,panel='lower',color='g',scatter=True)\n",
    "                               ]\n",
    "                    kwargs = dict(type='candle',figratio =(16,8),volume=False,figscale=1)#line，mav=(5,10)\n",
    "                    Kline_path ='/data/fjsdata/qtsys/real/'+code+'.png'\n",
    "                    save = dict(fname=Kline_path,dpi=100, pad_inches=0.2)\n",
    "                    mpf.plot(df_kline,**kwargs,addplot=apds,style='sas',savefig=save)#charles\n",
    "                    plt.close()\n",
    "                    Kline_img = cv2.resize(cv2.imread(Kline_path).astype(np.float32), (256, 256)) #read image \n",
    "                    teI = []\n",
    "                    teI.append(Kline_img)\n",
    "                    #output feature with model\n",
    "                    teI = torch.from_numpy(np.array(teI)).type(torch.FloatTensor).cuda()\n",
    "                    teI = best_net(teI.permute(0, 3, 1, 2))#forword\n",
    "                    teI = torch.tanh(teI) #[-1,1]\n",
    "                    teI = teI.cpu().data.numpy().tolist()\n",
    "                    scores, neighbors = gpu_index.search(np.ascontiguousarray(teI, dtype=np.float32), k=1) #return top1\n",
    "                    if scores.flatten()[0]< 0.001: #similarity for buy\n",
    "                        label = trY[neighbors.flatten()[0]] \n",
    "                        if label == 0: print('%s-B'%(code))\n",
    "                    else:os.remove(Kline_path) #remove the image file if no handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.83\n"
     ]
    }
   ],
   "source": [
    "quotation = easyquotation.use('sina')\n",
    "df = quotation.real('000651')\n",
    "price =  list(df.values())[0]['now']\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
