{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Model: BMF(Bayesian Matrix Factorization for Recommeder Systems).\n",
    "2. Datatset: MovieLens-1m:https://grouplens.org/datasets/movielens/  \n",
    "3. Evaluation: HR,NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import heapq\n",
    "import math\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import surprise as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: Interaction = 994169, User = 6040, Item = 3706, Sparsity = 0.0444\n",
      "The length of Testset: 604000\n"
     ]
    }
   ],
   "source": [
    "#trainset\n",
    "filePath = \"/data/fjsdata/BNMF/ml-1m.train.rating\" \n",
    "data = pd.read_csv(filePath, sep='\\t', header=None, names=['user', 'item', 'rating'], \\\n",
    "                                 usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.float})\n",
    "#data['rating']=data['rating'].apply(lambda x: 1.0 if float(x)>0.0 else 0.0)\n",
    "maxu, maxi = data['user'].max()+1, data['item'].max()+1\n",
    "print('Dataset Statistics: Interaction = %d, User = %d, Item = %d, Sparsity = %.4f' % \\\n",
    "                  (data.shape[0], maxu, maxi, data.shape[0]/(maxu*maxi)))\n",
    "trainset = data.values.tolist()\n",
    "trainMat = np.zeros([maxu, maxi], dtype=np.float32)\n",
    "for u,i,r in trainset:\n",
    "    trainMat[int(u)][int(i)] = float(r)\n",
    "#testset\n",
    "testset = []\n",
    "filePath = \"/data/fjsdata/BNMF/ml-1m.test.negative\" \n",
    "with open(filePath, 'r') as fd:\n",
    "    line = fd.readline()\n",
    "    while line != None and line != '':\n",
    "        arr = line.split('\\t')\n",
    "        u = eval(arr[0])[0]\n",
    "        testset.append([u, eval(arr[0])[1], 1.0])#first is one postive item\n",
    "        for i in arr[1:]:\n",
    "            testset.append([u, int(i), 0.0]) #99 negative items\n",
    "        line = fd.readline()\n",
    "print ('The length of Testset: %d'%(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Baselien: SVD with scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5=0.259272, NDCG@5=0.127297\n",
      "HR@10=0.258609, NDCG@10=0.125978\n",
      "HR@15=0.259106, NDCG@15=0.126195\n",
      "HR@20=0.258775, NDCG@20=0.126813\n"
     ]
    }
   ],
   "source": [
    "reader = sp.Reader(rating_scale=(0, 5))\n",
    "spdata = sp.Dataset.load_from_df(data,reader)\n",
    "trainset_svd = spdata.build_full_trainset()\n",
    "for K in [5,10,15,20]:#iterations epoches\n",
    "    algo = sp.SVD(n_factors=K, n_epochs=20, lr_all=0.001, reg_all=0.01 )#\n",
    "    algo.fit(trainset_svd)\n",
    "    predictions = algo.test(testset)#testset include one positive and 99 negtive sample of every user.\n",
    "    user_iid_true_est = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_iid_true_est[uid].append((iid, true_r, est))\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    for uid, iid_ratings in user_iid_true_est.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        #iid_ratings.sort(key=lambda x: x[2], reverse=True) #sorted by est\n",
    "        scorelist = []\n",
    "        positem = -1\n",
    "        for iid, ture_r, est in iid_ratings:\n",
    "            if positem == -1: positem=iid #one positive item in first\n",
    "            scorelist.append([iid,est])\n",
    "        map_item_score = {}\n",
    "        for item, rate in scorelist: #turn dict\n",
    "            map_item_score[item] = rate\n",
    "        ranklist = heapq.nlargest(10, map_item_score, key=map_item_score.get)#default Topn=10\n",
    "        hr = getHitRatio(ranklist, positem)\n",
    "        hits.append(hr)\n",
    "        ndcg = getNDCG(ranklist, positem)\n",
    "        ndcgs.append(ndcg)\n",
    "    hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print (\"HR@%d=%.6f, NDCG@%d=%.6f\" % (K, hitratio, K, ndcg))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. BMF: Bayesian Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@5=0.424338, NDCG@5=0.166753\n",
      "HR@10=0.409934, NDCG@10=0.160615\n",
      "HR@15=0.424172, NDCG@15=0.173028\n",
      "HR@20=0.413576, NDCG@20=0.162718\n"
     ]
    }
   ],
   "source": [
    "class BayesianMatrixFactorization():\n",
    "    \"\"\"\n",
    "    Bayesian Matrix Factorization model\n",
    "    R = PxQ\n",
    "    p ~ N(p|0, alpha^(-1)I)\n",
    "    q ~ N(q|0, alpha^(-1)I)\n",
    "    r = p @ q\n",
    "    t ~ N(r|p @ q, beta^(-1))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha_p:float=1., alpha_q:float=1., beta:float=1.):\n",
    "        \"\"\"\n",
    "        ----------\n",
    "        n_u, n_i: the number of users and items, respectively.\n",
    "        k : the number of latent factors\n",
    "        \"\"\"\n",
    "        self.alpha_p = alpha_p\n",
    "        self.alpha_q = alpha_q\n",
    "        self.beta = beta\n",
    "        #posterior of p,q \n",
    "        self.pos_mean_p = None\n",
    "        self.pos_precision_p = None\n",
    "        self.pos_mean_q = None\n",
    "        self.pos_precision_q = None\n",
    "\n",
    "    def fit(self, R:np.ndarray, k:int=5):\n",
    "        \"\"\"\n",
    "        bayesian update of parameters given training dataset\n",
    "        Parameters\n",
    "        ----------\n",
    "        R : (u,i) np.ndarray\n",
    "            training data independent variable, u is the number of users, i is the number of items.\n",
    "        k : int, the number of latent factors.\n",
    "        \"\"\"\n",
    "        #1. generate matrices P, Q\n",
    "        P = np.random.normal(0,self.alpha_p,(R.shape[0],k))#uxk\n",
    "        Q = np.random.normal(0,self.alpha_q,(R.shape[1],k))#ixk\n",
    "        #2.calculate the posterior with analytical solution\n",
    "        self.pos_precision_p = self.alpha_p + self.beta * Q @ Q.T # ixi\n",
    "        self.pos_mean_p = self.beta * R @ np.linalg.inv(self.pos_precision_p) @ Q # uxi,ixi,ixk -> uxk\n",
    "        self.pos_precision_q = self.alpha_q + self.beta * P @ P.T # uxu\n",
    "        self.pos_mean_q = self.beta * R.T @ np.linalg.inv(self.pos_precision_q) @ P # ixu,uxu,uxk -> ixk\n",
    "\n",
    "    def predict(self, sample_size:int=None):\n",
    "        \"\"\"\n",
    "        return mean  of predictive distribution\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_size : int, optional\n",
    "            number of samples to draw from the predictive distribution\n",
    "            (the default is None, no sampling from the distribution)\n",
    "        Returns\n",
    "        -------\n",
    "        R_pred : (u,i) np.ndarray\n",
    "            mean of the predictive distribution\n",
    "        R_pred_sample : (u,i,sample_size) np.ndarray\n",
    "            samples from the predictive distribution\n",
    "        \"\"\"\n",
    "        if sample_size is not None:\n",
    "            p_sample = np.random.multivariate_normal(self.pos_mean_p, np.linalg.inv(self.pos_precision_q), size=sample_size)\n",
    "            q_sample = np.random.multivariate_normal(self.pos_mean_q, np.linalg.inv(self.pos_precision_p), size=sample_size)\n",
    "            R_pred_sample_list=[]\n",
    "            for i in range(sample_size): \n",
    "                R_pred_sample_list.append( np.dot(p_sample, q_sample.T) )\n",
    "            R_pred_sample = np.mean(np.array(R_pred_sample_list), axis=0)\n",
    "            return  R_pred_sample #uxi\n",
    "        \n",
    "        R_pred = self.pos_mean_p @ self.pos_mean_q.T #R = PxQ\n",
    "        return R_pred #uxi\n",
    "\n",
    "\n",
    "for K in [5,10,15,20]:#iterations epoches\n",
    "    bmf = BayesianMatrixFactorization()\n",
    "    bmf.fit(R=trainMat, k=K)\n",
    "    R_pred = bmf.predict()\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    for c in range(0,maxu):#6040\n",
    "        scorelist = []\n",
    "        gtItem = -1\n",
    "        for u,i,r in testset[c*100:(c+1)*100]:#604000\n",
    "            if r == 1.0: gtItem = i\n",
    "            est = R_pred[int(u)][int(i)]\n",
    "            scorelist.append([i,est])\n",
    "        map_item_score = {}\n",
    "        for item, rate in scorelist: #turn dict\n",
    "            map_item_score[item] = rate\n",
    "        ranklist = heapq.nlargest(30, map_item_score, key=map_item_score.get)#topn=20\n",
    "        hr = getHitRatio(ranklist, gtItem)\n",
    "        hits.append(hr)\n",
    "        ndcg = getNDCG(ranklist, gtItem)\n",
    "        ndcgs.append(ndcg)\n",
    "    hitratio,ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print (\"HR@%d=%.6f, NDCG@%d=%.6f\" % (K, hitratio, K, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
